---
title: "07-test-LM-region-differences"
author: "Ariel Marcy"
date: "10/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '../eco-rodents')
#par(mfrow=c(1,1))
```

# Test variation within morphospace
What is causing high levels of allometry? Is it functional integration of the gnawing apparatus (mostly in the top cranium-rostrum area)? 

If so, we would expect to see the top cranium-rostrum to be the least variable across species compared to the basicranium-top cranium and basicranium-rostrum comparisons. 

### Load packages, functions, and data from previous steps
```{r message = FALSE}
library(png)  # needed to work with screenshots
library(colorspace)  # plot colors
# Load libraries (and install if necessary) for landvR package
if(!require(devtools)) install.packages("devtools")
if(!require(dispRity)) install.packages("dispRity")
if(!require(landvR)) install_github("TGuillerme/landvR")
library(data.table)
library(vegan)
library(geomorph)
source("../Functions/utilities.R")  # custom functions
load(file = "../Data/Processed/03-main-data.rda")
load(file = "../Data/Processed/03-tree-data.rda")
load(file = "../Data/Processed/03-graphing-vectors.rda")
load(file = "../Data/Processed/05-residual-data.rda")
```

## Choose the partitions
The three partitions will need to be designated from the LM numbers. The first time, this was done with `define.modules()` but each module was then saved in a .csv file so this step can be repeated much more quickly.

### Load in the partitions for all subsequent times
```{r}
lm.modules <- read.csv("../Data/Processed/Landmark_modules.csv", sep = ",", header = TRUE)
```

### Visualize the landmark types
```{r}
# Deconstruct function from Thomas's code in Landmark-test
ref <- mshape(shape)  
PartLevels <- unique(lm.modules[, 5])
Colors <- rainbow(length(PartLevels))
Colors <- c("blue", "gray", "black")  # semi, patch, fixed

# Subset the landmarks according to the partitions
Part <- list()
for(i in 1:length(PartLevels)){
        Part[[i]] <- which(lm.modules[, 5] == PartLevels[[i]])
}

# 3D plot of the partitions
open3d()
for (i in 1:length(PartLevels)){
        spheres3d(ref[Part[[i]], 1], ref[Part[[i]], 2], ref[Part[[i]], 3], col = Colors[i], lit = TRUE, radius = 0.001, asp = FALSE)
}
```

### Visualize the 3 partitions
```{r}
# Deconstruct function from Thomas's code in Landmark-test
ref <- mshape(shape)  
PartLevels <- unique(lm.modules[, 3])
Colors <- rainbow(length(PartLevels))
Colors <- c("brown", "gray",  "#79ABE2")  

# Subset the landmarks according to the partitions
Part <- list()
for(i in 1:length(PartLevels)){
        Part[[i]] <- which(lm.modules[, 3] == PartLevels[[i]])
}

# 3D plot of the partitions
open3d()
for (i in 1:length(PartLevels)){
        spheres3d(ref[Part[[i]], 1], ref[Part[[i]], 2], ref[Part[[i]], 3], col = Colors[i], lit = TRUE, radius = 0.001, asp = FALSE)
}
```

## Test modularity with 3 partitions
```{r}
# Rostrum versus top cranium and basicranium
mod.test.1 <- modularity.test(shape, partition.gp = (lm.modules[, 3]))
mod.test.1$CR.mat  # results

# And now a test with the phylogentic tree (and mean shapes)
mod.test.phy <- phylo.modularity(mean.shapes, partition.gp = lm.modules[, 3], aus.tree)
mod.test.phy$CR.mat
```

### Visualize the 6 partitions from Goswami 2006/7
```{r}
# Deconstruct function from Thomas's code in Landmark-test
PartLevels <- unique(lm.modules[, 4])  # 5 modules from Goswami's 6 (missing zygomatic)
Colors <- rainbow(length(PartLevels))

# Subset the landmarks according to the partitions
Part <- list()
for(i in 1:length(PartLevels)){
  Part[[i]] <- which(lm.modules[, 4] == PartLevels[[i]])
}

# 3D plot of the partitions
open3d()
for (i in 1:length(PartLevels)){
  spheres3d(ref[Part[[i]], 1], ref[Part[[i]], 2], ref[Part[[i]], 3], col = Colors[i], lit = TRUE, radius = 0.001, asp = FALSE)
  rgl.texts(ref[Part[[i]], 1], ref[Part[[i]], 2], ref[Part[[i]], 3], lm.modules[, 1], offset = 100, color = c("black"))
}
```

## Test modularity with 5 partitions
This test uses covariance ratio (CR) coefficients (Adams 2016) to quantify the degree of modularity between hypothesized modules/partitions. The observed CR is compared to the distribution found by randomizing the landmarks into partitions of identical sample sizes.

A significant modular signal: when the observed CR coefficient is significantly lower than the distribution of the randomized CR coefficients
```{r}
# Rostrum versus top cranium and basicranium
mod.test.5 <- modularity.test(shape, partition.gp = (lm.modules[, 4]))

# Make pairwise comparison table
mod.result <- as.matrix(mod.test.5$CR.mat)  # results
colnames(mod.result) <- c("vault", "orbital", "basicran", "rostrum", "molar")
rownames(mod.result) <- c("vault", "orbital", "basicran", "rostrum", "molar")

plot(mod.test.5)

# And now with the phylogentic tree (and mean shapes)
mod.test.5.phy <- phylo.modularity(mean.shapes, partition.gp = lm.modules[, 4], aus.tree)

# Make pairwise comparison table
mod.result.phy <- as.matrix(mod.test.5.phy$CR.mat)  # results
colnames(mod.result.phy) <- c("vault", "orbital", "basicran", "rostrum", "molar")
rownames(mod.result.phy) <- c("vault", "orbital", "basicran", "rostrum", "molar")

plot(mod.test.5.phy)
```

### Test if modularity signal is different across clades
```{r}
coords.clade <- coords.subset(mean.shapes, info.means$Clade)

# Remove single-species clades
clade.index <- 1:nlevels(info.means$Clade)[-c(4,5)]  # removes Mus and Pogonomys

# Use lapply function to perform modularity test on 3D arrays in each clade
mod.clade.tests <- lapply(clade.index, function(j) modularity.test(coords.clade[[j]], partition.gp = lm.modules[, 4], iter = 500, print.progress = FALSE))

# Apply function from 2019 Adams & Collyer paper
clade.CRs <- compare.CR(mod.clade.tests, CR.null = FALSE)
clade.CRs
```

### Test if modularity signal is different across tribes
```{r}
coords.tribe <- coords.subset(mean.shapes, info.means$Endemic)

# Use lapply function to perform modularity test on 3D arrays in each tribe
mod.tribe.tests <- lapply(c(2,3), function(j) modularity.test(coords.tribe[[j]], partition.gp = lm.modules[, 4], iter = 500, print.progress = TRUE))

# Apply function from 2019 Adams & Collyer paper
tribe.CRs <- compare.CR(mod.tribe.tests, CR.null = FALSE)
tribe.CRs
```

## Test to see if PCs of modules are equivalent
Uses method by Dr Emma Sherratt
```{r}
# Separate modules - using 5-module framework 
mod.1 <- mean.shapes[which(lm.modules[, 4] == "basicran"), ,]
mod.2 <- mean.shapes[which(lm.modules[, 4] == "molar"), ,]
mod.3 <- mean.shapes[which(lm.modules[, 4] == "orbital"), ,]
mod.4 <- mean.shapes[which(lm.modules[, 4] == "rostrum"), ,]
mod.5 <- mean.shapes[which(lm.modules[, 4] == "vault"), ,]

# Run PCAs
PCA.1 <- plotTangentSpace(mod.1)
PCA.2 <- plotTangentSpace(mod.2)
PCA.3 <- plotTangentSpace(mod.3)
PCA.4 <- plotTangentSpace(mod.4)
PCA.5 <- plotTangentSpace(mod.5)

# Make distance matrices
d.PCA.1 <- dist(PCA.1$pc.scores)
d.PCA.2 <- dist(PCA.2$pc.scores)
d.PCA.3 <- dist(PCA.3$pc.scores)
d.PCA.4 <- dist(PCA.4$pc.scores)
d.PCA.5 <- dist(PCA.5$pc.scores)

# Run Mantel tests
m.1v2 <- mantel(d.PCA.1, d.PCA.2, method = "pearson", permutations = 1000) 
m.1v3 <- mantel(d.PCA.1, d.PCA.3, method = "pearson", permutations = 1000)
m.1v4 <- mantel(d.PCA.1, d.PCA.4, method = "pearson", permutations = 1000)
m.1v5 <- mantel(d.PCA.1, d.PCA.5, method = "pearson", permutations = 1000)

m.2v3 <- mantel(d.PCA.2, d.PCA.3, method = "pearson", permutations = 1000) 
m.2v4 <- mantel(d.PCA.2, d.PCA.4, method = "pearson", permutations = 1000)
m.2v5 <- mantel(d.PCA.2, d.PCA.5, method = "pearson", permutations = 1000)

m.3v4 <- mantel(d.PCA.3, d.PCA.4, method = "pearson", permutations = 1000)
m.3v5 <- mantel(d.PCA.3, d.PCA.5, method = "pearson", permutations = 1000)

m.4v5 <- mantel(d.PCA.4, d.PCA.5, method = "pearson", permutations = 1000)

# Bonferroni correction
p.vals.bon <- round(p.adjust(c(m.1v2$signif, m.1v3$signif, m.1v4$signif, m.1v5$signif, m.2v3$signif, m.2v4$signif, m.2v5$signif, m.3v4$signif, m.3v5$signif, m.4v5$signif), method = "bonferroni"), 3)

# Make results table
col1 <- c("-", p.vals.bon[1], p.vals.bon[2], p.vals.bon[3], p.vals.bon[4])
col2 <- c(m.1v2$statistic, "-", p.vals.bon[5], p.vals.bon[6], p.vals.bon[7])
col3 <- c(m.1v3$statistic, m.2v3$statistic, "-", p.vals.bon[8], p.vals.bon[9])
col4 <- c(m.1v4$statistic, m.2v4$statistic, m.3v4$statistic, "-", p.vals.bon[10])
col5 <- c(m.1v5$statistic, m.2v5$statistic, m.3v5$statistic, m.4v5$statistic, "-")

modules <- sort(unique(as.factor(lm.modules[, 4])))
mantel.results <- data.table(basicran = col1, molar = col2, orbital = col3, rostrum = col4, vault = col5, row.names = modules)

# Export Table S6
write.table(mantel.results, "../Data/Results/Table_MantelTests.csv", sep = ",", col.names = NA)
```

## Integration test
With 5 modules 
```{r}
int.test <- integration.test(mean.shapes, partition.gp = lm.modules[, 4], iter = 1000)
summary(int.test)
int.test$r.pls.mat

# With phylogeny
int.phylo.test <- phylo.integration(mean.shapes, phy = aus.tree, partition.gp = lm.modules[, 4], iter = 1000)
summary(int.phylo.test)
```

## Integration test
With 3 modules 
```{r}
int.test <- integration.test(mean.shapes, partition.gp = lm.modules[, 3], iter = 500)
summary(int.test)
int.test$r.pls.mat

# With phylogeny
int.phylo.test <- phylo.integration(mean.shapes, phy = aus.tree, partition.gp = lm.modules[, 3], iter = 500)
summary(int.phylo.test)
```

### Whole integration test
Test whether rodent skull is integrated as a whole
```{r}
globalIntegration(mean.shapes)
```