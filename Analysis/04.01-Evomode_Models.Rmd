---
title: "04-compare_PCAs"
author: "Ariel Marcy & Vera Weisbecker"
date: "8/15/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = '../eco-rodents')
```

# Plot PCAs for allometric and shape residual datasets
Plot PCAs for allometric shape and shape residual, provide coloration and pch symbols by locomotion and diet, and visualize changes in shape residual PCA when *Notomys* species are removed. These plots are relevant to the heatplots created in script 05 / shown in Figure 2. 

Creates multipanel Figure 1.

Compares morphospace similarity of the two datasets with Mantel tests and a correlation test.

Creates supplementary Figure 1, a screeplot of the the PCs for each dataset.

Produces shape residual data used in later analyses, stored in rda file 04.

### Load packages, functions, and data
Tree, mean shape, and metadata for phylogenetic analyses come from the allometry rodents script 04. 
```{r message = FALSE}
library(geomorph)   
library(vegan)      
library(dplyr)      
library(colorspace) 
library(phytools) 
library(geiger)      
library(mvMORPH)  
library(qpcR)


# This sets the wd to local
library(rstudioapi) # Safely Access the RStudio API
setwd(dirname(getActiveDocumentContext()$path))

source("../Functions/utilities.R")  # custom functions
load(file = "../Data/Processed/03-main-data.rda")
load(file = "../Data/Processed/03-tree-data.rda")
load(file = "../Data/Processed/03-graphing-vectors.rda")
```

#Phylogenetic signal of shape and size
```{r}

#the tests and below phytools tests needs names with the data so pulling them out just here
Csizes_fit <- info.means$MeanCsize
names(Csizes_fit) <- paste(info.means$Genus.y, "_", info.means$Species.y, sep="")

#always check!!
names(Csizes_fit) == aus.tree$tip.label
dimnames(mean.shapes)[[3]]==aus.tree$tip.label

physignal(mean.shapes, aus.tree )

physignal(log(Csizes_fit), aus.tree )

```
#which model of evolution does shape follow? Using Julien Clavel's mvMorph package

```{r}

two_d_array <- list( array2d=two.d.array(mean.shapes))

#A little check that things line up: 

dimnames(two_d_array$array2d)[[1]] == aus.tree$tip.label



load(file="../Data/Processed/Shape_evo_modes")
#Fitting different evolutionary models to the shape data and tabulating the GICs. The BM analysis takes 5 minutes, the other two take longer - looking at nearly 30 minutes of computing time!

#BM_shapefit <- mvgls(array2d ~ 1 , aus.tree, data = two_d_array, model="BM" , method="PL-LOOCV")
#OU_shapefit <- mvgls(array2d ~ 1 , aus.tree, data = two_d_array, model="OU" , method="PL-LOOCV")
#EB_shapefit <- mvgls(array2d ~ 1 , aus.tree, data = two_d_array, model="EB" , method="PL-LOOCV")
#save(BM_shapefit,OU_shapefit,EB_shapefit, file="../Data/Processed/Shape_evo_modes")

GIC_BM<- GIC(BM_shapefit)
GIC_OU <- GIC(OU_shapefit)
GIC_EB <- GIC(EB_shapefit)

#Compute vector of GICs - this also takes a little, ~1 minute
GICs=unlist(c(GIC(BM_shapefit)[2],GIC(OU_shapefit)[2],GIC(EB_shapefit)[2] ))

names(GICs) <- c("BM", "OU", "EB" )
  
#compute relative probabilities betweeen 0 and 1 by comparing AICS according to Burnham and Anderson (2002)
GICmin=GICs-min(GICs)
  W=exp(-0.5*GICmin)/sum(exp(-0.5*GICmin))
  
  #OU is by far the preferred model
  W 

#or use the evidence ratio computed in the qprc package

Evidence_ratios <- c(evidence(GICs[1], GICs[2]), evidence(GICs[1], GICs[3]), evidence(GICs[2], GICs[3]))

names(Evidence_ratios)<- c("BM_OU", "BM_EB", "OU_EB")

#" If large, first model is better. If small, second model is better. "
#OU is also better here - infinitely better than EB by the looks of it!

Evidence_ratios
  


#How strong is the OU process - is it OK to use BM for analyses? Using reasoning and workflow from Artuso et al. 2022:
#For those modules following an OU process, we calculated the “rate of adaptation” parameter, α, and its associated “phylogenetic half-life” (t1/2), as given by the formula (Hansen 1997, 2014): t1/2 = ln2/α, assuming a tree height of about 11.5 million years (Myr), based on the crown age of Clade A (Gamisch et al. 2021; see also Fig. S1). Phylogenetic half-lives are usually interpreted as the average time it takes a species to evolve halfway from its ancestral state (here: module shape) toward the optimum (see also Artuso et al. 2021), thereby indicating the strength of the OU process acting on the species. When α is zero and/or t1/2 is larger relative to tree height, the OU model collapses to the BM model (Beaulieu et al. 2012; Cooper et al. 2016).

#This is alpha (based on summary(OU_shapefit)) - it is 0.13
alpha <- OU_shapefit$opt$par[2]

#The deepest node is 37 but t1/2 is calculated as 5.28, so the OU model is not particularly BM-like 
max(node.depth(aus.tree))

log(2)/alpha

#But with small sample sizes, Type I error rates are high and common likelihood tests such as AIC can be biased (cooper et al. 2016)


#Does it make much of a difference to the coordinates if we adjust for OU vs BM evolution? 

#trying to do what I would usually do if I ran pgls:
resid_BM <- arrayspecs(BM_shapefit$residuals, dim(mean.shapes)[[1]], 3)
#trying to do what I would usually do if I ran pgls:
resid_OU <- arrayspecs(OU_shapefit$residuals, dim(mean.shapes)[[1]], 3)

#The r-pls of these residuals is 1
integration.test(resid_BM, resid_OU)


```
Now fitting a model just for size, using Phytools

```{r}



sizeBM<-fitContinuous(aus.tree,log(Csizes_fit))
sizeOU<-fitContinuous(aus.tree,log(Csizes_fit),model="OU")
#EB gives a warning message?
sizeEB<-fitContinuous(aus.tree,log(Csizes_fit),model="EB")

#Compute vector of GICs - this also takes a little, ~1 minute
AICs=c(sizeBM$opt$aic,sizeOU$opt$aic,sizeEB$opt$aic )

names(AICs) <- c("BM", "OU", "EB" )
  
#compute relative probabilities betweeen 0 and 1 by comparing AICS according to Burnham and Anderson (2002)
AICmin=AICs-min(AICs)
  W=exp(-0.5*AICmin)/sum(exp(-0.5*AICmin))
  
  #OU is by far the preferred model
  W 


```
#allometry
```{r}
#a paranoid check - don't judge me, I have ADHD :-D
names(Csizes_fit)==dimnames(two_d_array$array2d)[[1]]
names(Csizes_fit)==aus.tree$tip.label

load(file="../Data/Processed/Allom_evo_modes")

#or re-compute, the below also takes ~30 minutes on my fasted computer

# BM_allomfit <- mvgls(array2d ~ log(Csizes_fit), aus.tree, data = two_d_array, model="BM" , method="PL-LOOCV")
# OU_allomfit <- mvgls(array2d ~ log(Csizes_fit), aus.tree, data = two_d_array, model="OU" , method="PL-LOOCV")
# EB_allomfit <- mvgls(array2d ~ log(Csizes_fit), aus.tree, data = two_d_array, model="EB" , method="PL-LOOCV")
# save(BM_allomfit,OU_allomfit,EB_allomfit, file="../Data/Processed/Allom_evo_modes")

GIC_BM_allom<- GIC(BM_allomfit)
GIC_OU <- GIC(OU_allomfit)
GIC_EB <- GIC(EB_allomfit)

#Compute vector of GICs - this also takes a little, ~1 minute
GICs=unlist(c(GIC(BM_allomfit)[2],GIC(OU_allomfit)[2],GIC(EB_allomfit)[2] ))

names(GICs) <- c("BM", "OU", "EB" )
  
#compute relative probabilities betweeen 0 and 1 by comparing AICS according to Burnham and Anderson (2002)

GICmin=GICs-min(GICs)
  W=exp(-0.5*GICmin)/sum(exp(-0.5*GICmin))

#OU is also strongly preferred here.
  W 

#or use the evidence ratio computed in the qprc package

Evidence_ratios <- c(evidence(GICs[1], GICs[2]), evidence(GICs[1], GICs[3]), evidence(GICs[2], GICs[3]))

names(Evidence_ratios)<- c("BM_OU", "BM_EB", "OU_EB")

#" If large, first model is better. If small, second model is better. "

Evidence_ratios

#Alpha  
OU_allomfit$opt$par[2]

```
#extract shape residuals from OU model
```{r}
OU_allomfit$residuals

#trying to do what I would usually do if I ran pgls:
allom_resid_OU <- arrayspecs(OU_allomfit$residuals, dim(mean.shapes)[[1]], 3)

#also compute residuals from a pgls (Brownian-based) model
allom_GDF <- geomorph.data.frame(coords = mean.shapes, Csize = info.means$MeanCsize)
allometry.all <- procD.pgls(coords ~ log(Csize), aus.tree, data = allom_GDF)

# Turn the residuals into an appropriate array
dimnames(mean.shapes)[[3]] <- info.means$FullName
allom_resid_PGLS <- arrayspecs(allometry.all$pgls.residuals, dim(mean.shapes)[[1]], 3)

#compare the two types of residuals
#they match
dimnames(allom_resid_PGLS)[[3]]==dimnames(allom_resid_OU)[[3]]

head(allom_resid_PGLS)
head(allom_resid_OU)


#using the integration.test function which is essentially a 2BPLS - the residuals of the two models are nearly identical
integration.test(allom_resid_PGLS,allom_resid_OU)

```

#After finding that the residuals of the OU and the residuals of the conventional pgls model correlate at r-PLS=1 (same with just the residuals of just modelling shape evolution under BM/OU), deciding to continue with just pgls-based analyses. It's unlikely that we will get substantial differences. 

#Now we want to know if allometry affects all modules equally. For this, make separate gpas first: GPA of all specimens and then create mean shapes.

```{r}

basicran <- mean.shapes[which(lm.modules[, 4] == "basicran"), ,]
molar <- mean.shapes[which(lm.modules[, 4] == "molar"), ,]
orbital <- mean.shapes[which(lm.modules[, 4] == "orbital"), ,]
rostrum <- mean.shapes[which(lm.modules[, 4] == "rostrum"), ,]
vault <- mean.shapes[which(lm.modules[, 4] == "vault"), ,]

GPA_list <- list( basicran=basicran, molar=molar, orbital=orbital, rostrum=rostrum, vault=vault)


#Create all combinations of modules
Combinations <- expand.grid(names(module_list), names(module_list))

#add empty colums for values
Combinations[,c("Allometry", "p")] <- NA


for (i in 1:nrow(Combinations)){
  
temp <- procD.pgls(module_list[[which(names(module_list)==Combinations[i,1])]] ~ log(CSIZE FROM GPA)
                          phy=aus.tree)

Combinations$Rpls[i]<-temp$r.pls
Combinations$p[i] <- temp$P.value

}


R_pls_matrix <- matrix(Combinations$Rpls, nrow=5, ncol=5, dimnames=list(names(module_list),names(module_list)))

write.csv(R_pls_matrix, file="../Data/Results/Module_allometry.csv")

#manual tests to make sure the matrix reflects reality - it does

phylo.integration(basicran, molar, phy=aus.tree)
phylo.integration(rostrum, molar, phy=aus.tree)
phylo.integration(molar, rostrum, phy=aus.tree)

#Now create a matrix that asks if the levels of integration are significantly different using compare.pls

#Create all combinations of modules

#create expand grid matrix but this time take out self-combinations - reduces it to 20 rows. I initially used this but it doubles up on combinations.
#Combinations_compare <- expand.grid(names(module_list), names(module_list))

#The following is better:

Combinations_compare <- c( names(module_list), names(module_list) )
Combinations_compare <- unique( Combinations_compare )
Combinations_compare <- combn( Combinations_compare , 2 )
#Combinations_compare <- paste(Combinations_compare[1,], Combinations_compare[2,])









```





```{r}
#The above code was implemented for revision of this paper. Here I'm just changing the name of the residual object so the rest of the code doesn't have to be fixed.
allom.resid <- allom_resid_PGLS
# Add the consensus shape (from the GPA) to the residuals if you want to understand the landmark variation in the residuals - needed for script 06
gpa <- gpagen(mean.shapes)
residuals <- allom.resid + array(gpa$consensus, dim(allom.resid))
```

### Prepare evolutionary allometry information (from AmNat paper) for Fig 1
```{r}
# Run Procrustes ANOVA with interaction
pgls.gdf <- geomorph.data.frame(coords = mean.shapes, size = info.means$MeanCsize, clade = info.means$Clade)

fit.pgls <- procD.pgls(coords ~ log(size) * clade, aus.tree, iter = 500, data = pgls.gdf, print.progress = FALSE)

# Find Reg Score values for plotting purposes
evo.allo.rs <- plotAllometry(fit.pgls, size = info.means$MeanCsize, method = "RegScore")
```

### Export Figure 1 to pdf
Finally, we compare the full shape PCA to the shape residuals PCAs. All PCAs are relevant to Figure 2 heatmaps.
```{r}
# Set up Notomys abline
not.index <- which(info.means$Genus.y == "Notomys")
not.Reg <- evo.allo.rs$RegScore[not.index]
not.Cs <- info.means$MeanCsize[not.index]

# Set up for export and for multiple panels
part.coords <- c(-0.117, 0.095)  # plotting parameters for A, C, D, E placement

#setEPS()
#postscript("../Data/Results/Figure1_PCAs_6plot.eps")
mat <- matrix(c(1:6), 3, 2, byrow = TRUE)  # 6 plots, 3 rows, 2 columns
layout(mat, widths = rep(1, dim(mat)[2]), heights = rep(0.5, dim(mat)[1]))   

# A) FULL SHAPE PCA - diet & locomotion legend
par(mar = c(4.5, 4.5, 2, 1))
plot(x = -mean.PCA$x[, 1],  # Flip for consistency
                 y = mean.PCA$x[, 2],  
                 xlab = "PC1 (52.3%)", 
                 ylab = "PC2 (14.5%)",
                 xlim = c(-0.12, 0.12),
                 ylim = c(-0.1, 0.1),
                 col = col.diet.means, 
                 pch = pch.gld.means, 
                 bg = col.diet.means,
                 cex = 1.5,
                 cex.axis = 1.1, 
                 cex.lab = 1.3)
text(part.coords[1], part.coords[2], "a", cex = 1.5)
text(-0.045, 0.092, "full shape dataset (ecology)")
text(-0.078, 0.075, expression(paste("Marcy ", italic("et al. "), "2020")), cex = 0.8)

legend(-0.131, 0.067, legend = c("Arboreal", "Hopping", "Terrestrial", "Semiaquatic", "", "Carnivore", "Frugivore", "Granivore", "Folivore", "Omnivore"), col = c(rep("black", 4), "white", col.diet.5), border = NULL, pch = c(24:21, rep(16, 6)), cex = 0.8, bty = "n")

# B) Evolutionary Allometry plot - diet & locomotion legend
par(mar = c(4, 4, 1, 1))
plot(x = log(info.means$MeanCsize),
     y = -evo.allo.rs$RegScore,
     xlim = c(4.75, 6),
     col = col.diet.means, 
     pch = pch.gld.means, 
     bg = col.diet.means,
     main = " ",
     xlab = "Log centroid size", 
     ylab = "Shape  (Reg Score)",
     bty = "n")
text(4.8, 0.006, "b", cex = 1.5)
text(5.1, 0.0058, "evolutionary allometry")
abline(lm(-evo.allo.rs$RegScore ~ log(info.means$MeanCsize)), col = "dark grey", lwd = 1)  # common evolutionary allometry line
#adding a line of the lm model as well
abline(lm(mean.shapes~log(info.means$MeanCsize)), col = "dark grey", lwd = 1)
#text(x = log(info.means$MeanCsize), y = -evo.allo.rs$RegScore, labels = info.means$Genus)  # labels genera on plot points

# C) FULL SHAPE PCA - genus colors
par(mar = c(4.5, 4.5, 2, 1))
plot(x = -mean.PCA$x[, 1],  # flip for consistency
                 y = mean.PCA$x[, 2],  
                 xlab = "PC1 (52.3%)", 
                 ylab = "PC2 (14.5%)",
                 xlim = c(-0.12, 0.12),
                 ylim = c(-0.1, 0.1),
                 col = alpha.col,
                 pch = 16,
                 bg = alpha.col,
                 cex = 1.5,
                 cex.axis = 1.1, 
                 cex.lab = 1.3)
text(part.coords[1], part.coords[2], "c", cex = 1.5)
text(-0.046, 0.092, "full shape dataset (genera)")

legend("bottomleft", legend = genera.phylo.full, col = col.phylo, pch = 16, cex = 0.68, pt.cex = 0.85, bty = "n", text.font = 3)

# D) shape residuals PCA - genus colors
par(mar = c(4.5, 4.5, 2, 1))
plot(x = res.PCA$x[, 1],  # no flip for consistency
                 y = -res.PCA$x[, 2],  
                 xlab = "PC1 (26.8%)", 
                 ylab = "PC2 (18.6%)",
                 xlim = c(-0.12, 0.12),
                 ylim = c(-0.1, 0.1),
                 col = alpha.col,
                 pch = 16,
                 bg = alpha.col,
                 cex = 1.5,
                 cex.axis = 1.1, 
                 cex.lab = 1.3)
text(part.coords[1], part.coords[2], "d", cex = 1.5)
text(-0.035, 0.092, "shape residual dataset (genera)")

# E) No Notomys shape residuals PCA - genus colors
par(mar = c(4.5, 4.5, 2, 1))
plot(x = wrap.PCA.r.n$x[, 1],  
                 y = wrap.PCA.r.n$x[, 2],  # no flip for consistency
                 xlab = "PC1 (30.1%)", 
                 ylab = "PC1 (16.7%)",
                 xlim = c(-0.12, 0.12),
                 ylim = c(-0.1, 0.1),
                 col = alpha.col.no, 
                 pch = 16, 
                 bg = alpha.col.no,
                 cex = 1.5,
                 cex.axis = 1.1, 
                 cex.lab = 1.3)
text(part.coords[1], part.coords[2], "e", cex = 1.5)
text(-0.034, 0.092, expression(paste("shape residual without ", italic("Notomys"))))

# F) shape Residuals PCA - ecology
par(mar = c(4.5, 4.5, 2, 1))
plot(x = res.PCA$x[, 1],  # no flip for consistency
                 y = -res.PCA$x[, 2],  
                 xlab = "PC1 (26.8%)", 
                 ylab = "PC1 (18.6%)",
                 xlim = c(-0.12, 0.12),
                 ylim = c(-0.1, 0.1),
                 col = col.diet.means, 
                 pch = pch.gld.means, 
                 bg = col.diet.means,
                 cex = 1.5,
                 cex.axis = 1.1, 
                 cex.lab = 1.3)
text(part.coords[1], part.coords[2], "f", cex = 1.5)
text(-0.053, 0.092, "shape residual (ecology)")

dev.off()
```

## 2) Compare the full shape and shape residual datasets
Mantel tests to compare full shape morphospace to the shape residual morphospace
```{r}
#A quick check of the correlation betwen full shape PC2 and residual shape PC1:
cor(mean.PCA$x[,2], res.PCA$x[,1])


# Make distance matrices
d.full.pca <- dist(mean.PCA$x)
d.res.pca <- dist(res.PCA$x)

# Mantel test for all PC scores
man.all <- mantel(d.full.pca, d.res.pca, method = "pearson", permutations = 1000) 
man.all$statistic
man.all$signif
```

### Mantel tests to compare just the 3 most important PCs
```{r}
# Make distance matrices
d.full.pc <- dist(mean.PCA$x[, 1:3])
d.res.pc <- dist(res.PCA$x[, 1:3])

# Mantel test for all PC scores
man.pc13 <- mantel(d.full.pc, d.res.pc, method = "pearson", permutations = 1000) 
man.pc13$statistic
man.pc13$signif
```

### Comaparison of morphospaces without allometric PC1
```{r}
# Make distance matrices
d.full.wo1 <- dist(mean.PCA$x[, 2:dim(mean.PCA$x)[2]])
d.res.woL <- dist(res.PCA$x[, 1:dim(res.PCA$x)[2]-1])

# Mantel test for all PC scores
man.pc.wo1 <- mantel(d.full.wo1, d.res.woL, method = "pearson", permutations = 1000) 
man.pc.wo1$statistic
man.pc.wo1$signif
```


### Correlation of residual PC1 to full shape PC2 and vice versa
```{r}
cor.pc1 <- cor(mean.PCA$x[, 2], -res.PCA$x[, 1])
cor.pc1

cor.pc2 <- cor(mean.PCA$x[, 1], res.PCA$x[, 2])
cor.pc2

cor.pc2v3 <- cor(mean.PCA$x[, 3], res.PCA$x[, 2])
cor.pc2v3
```

### Correlation of full shape PC1 and residual PC2 to centroid size
```{r}
cor.size <- cor(-mean.PCA$x[, 1], info.means$MeanCsize)
cor.size

# Correlation of PC2 to centroid size
cor.pc2.size <- cor(res.PCA$x[, 2], info.means$MeanCsize)
cor.pc2.size
```


## 3) Export skreeplots for PC importance scores for 3 separate datasets
Set up 3 datasets for screeplots
```{r}
# Full shape
full.PC.impt <- data.frame(PC = 1:(length(summary(mean.PCA)$PC.summary)), impt = unlist(summary(mean.PCA)[[1]][2,]))

# Shape residual
res.PC.impt <- data.frame(PC = 1:(length(summary(res.PCA)$PC.summary)), impt = unlist(summary(res.PCA)[[1]][2,]))

# Shape residual without Notomys wrap.PCA.r.n
rnot.PC.impt <- data.frame(PC = 1:(length(summary(wrap.PCA.r.n)$PC.summary)), impt = unlist(summary(wrap.PCA.r.n)[[1]][2,]))

```

### Create supplementary figure 1
```{r}
# Make simple multipanel figure
pdf("../Data/Results/SFigure1_Screeplots.pdf")
mat <- matrix(c(1:3), 3, 1, byrow = TRUE)  # 3 plots, 3 rows, 1 column
layout(mat, widths = rep(0.5, dim(mat)[2]), heights = rep(0.25, dim(mat)[1])) 

# 1) 
barplot(full.PC.impt[, 2], ylim = c(0, 0.5))
abline(h = 0.1, col = 'deeppink4')
mtext("A) full shape dataset", 3, line = 1.5, cex = 0.9, adj = 0, col = "black")
mtext("% of variance", 2, line = 2.5, cex = 0.83, col = "black")

# 2)
barplot(res.PC.impt[, 2], ylim = c(0, 0.5))
abline(h = 0.1, col = 'deeppink4')
mtext("B) shape residual dataset", 3, line = 1, cex = 0.9, adj = 0, col = "black")
mtext("% of variance", 2, line = 2.5, cex = 0.83, col = "black")

# 3)
barplot(rnot.PC.impt[, 2], ylim = c(0, 0.5))
abline(h = 0.1, col = 'deeppink4')
mtext(expression(paste("C) shape residual dataset without ", italic(Notomys))), 3, line = 1, cex = 0.9, adj = 0, col = "black")
mtext("% of variance", 2, line = 2.5, cex = 0.83, col = "black")
mtext("Principal component", 1, line = 1, cex = 0.83, col = "black")

dev.off()
```

### Save intermediate data
```{r}
save(mean.PCA, res.PCA, allom.resid, residuals, file = "../Data/Processed/04-residual-data.rda")
```
